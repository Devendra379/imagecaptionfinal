{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de494607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:33:42.636060Z",
     "iopub.status.busy": "2023-10-15T17:33:42.635412Z",
     "iopub.status.idle": "2023-10-15T17:33:52.270002Z",
     "shell.execute_reply": "2023-10-15T17:33:52.269053Z"
    },
    "id": "xeEuheqN160Y",
    "papermill": {
     "duration": 9.647467,
     "end_time": "2023-10-15T17:33:52.272211",
     "exception": false,
     "start_time": "2023-10-15T17:33:42.624744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "#from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical,plot_model\n",
    "from keras.layers import Input,Dense,LSTM,Embedding,Dropout,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac7646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:33:52.290645Z",
     "iopub.status.busy": "2023-10-15T17:33:52.290086Z",
     "iopub.status.idle": "2023-10-15T17:33:52.295522Z",
     "shell.execute_reply": "2023-10-15T17:33:52.294644Z"
    },
    "id": "KmwaM3eorvBC",
    "papermill": {
     "duration": 0.016503,
     "end_time": "2023-10-15T17:33:52.297423",
     "exception": false,
     "start_time": "2023-10-15T17:33:52.280920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205b2c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:33:52.314596Z",
     "iopub.status.busy": "2023-10-15T17:33:52.314344Z",
     "iopub.status.idle": "2023-10-15T17:33:52.318019Z",
     "shell.execute_reply": "2023-10-15T17:33:52.317204Z"
    },
    "id": "ykvzpkpH4chX",
    "papermill": {
     "duration": 0.013865,
     "end_time": "2023-10-15T17:33:52.319641",
     "exception": false,
     "start_time": "2023-10-15T17:33:52.305776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir=\"../flickr8k/\"\n",
    "working_dir=\"../flickr8k/Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6013b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:33:52.337416Z",
     "iopub.status.busy": "2023-10-15T17:33:52.336085Z",
     "iopub.status.idle": "2023-10-15T17:34:01.756914Z",
     "shell.execute_reply": "2023-10-15T17:34:01.755923Z"
    },
    "id": "AVWz6o2n5Ahu",
    "outputId": "afd0973a-87cb-46f4-9d18-adb872e2e2df",
    "papermill": {
     "duration": 9.431805,
     "end_time": "2023-10-15T17:34:01.759099",
     "exception": false,
     "start_time": "2023-10-15T17:33:52.327294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=VGG16()\n",
    "model=Model(inputs=model.inputs,outputs=model.layers[-2].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb13cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:34:01.780638Z",
     "iopub.status.busy": "2023-10-15T17:34:01.780089Z",
     "iopub.status.idle": "2023-10-15T17:34:01.823016Z",
     "shell.execute_reply": "2023-10-15T17:34:01.822226Z"
    },
    "id": "9sqXEiU_ipzJ",
    "outputId": "a67b08c8-36ea-4632-b020-e9563ae0a3a3",
    "papermill": {
     "duration": 0.083503,
     "end_time": "2023-10-15T17:34:01.852785",
     "exception": false,
     "start_time": "2023-10-15T17:34:01.769282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d2259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:34:01.878695Z",
     "iopub.status.busy": "2023-10-15T17:34:01.878421Z",
     "iopub.status.idle": "2023-10-15T17:34:03.148394Z",
     "shell.execute_reply": "2023-10-15T17:34:03.147407Z"
    },
    "id": "AcevtC_lc5fJ",
    "papermill": {
     "duration": 1.285216,
     "end_time": "2023-10-15T17:34:03.150571",
     "exception": false,
     "start_time": "2023-10-15T17:34:01.865355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights('model_resnet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa0b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:34:03.179658Z",
     "iopub.status.busy": "2023-10-15T17:34:03.179342Z",
     "iopub.status.idle": "2023-10-15T17:44:30.590598Z",
     "shell.execute_reply": "2023-10-15T17:44:30.589630Z"
    },
    "id": "tcgmmdH39fib",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cb8b0497-5c16-4218-ac0a-70275bd72c7b",
    "papermill": {
     "duration": 627.426774,
     "end_time": "2023-10-15T17:44:30.592386",
     "exception": false,
     "start_time": "2023-10-15T17:34:03.165612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = {}\n",
    "directory = os.path.join(base_dir, 'Images')\n",
    "\n",
    "for img_name in tqdm(os.listdir(directory)):\n",
    "    # load the image from file\n",
    "    img_path = directory + '/' + img_name\n",
    "    image = load_img(img_path, target_size=(224, 224))\n",
    "    # convert image pixels to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # preprocess image for vgg\n",
    "    image = preprocess_input(image)\n",
    "    # extract features\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    # get image ID\n",
    "    image_id = img_name.split('.')[0]\n",
    "    # store feature\n",
    "    features[image_id] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e281c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:30.619034Z",
     "iopub.status.busy": "2023-10-15T17:44:30.618441Z",
     "iopub.status.idle": "2023-10-15T17:44:30.625125Z",
     "shell.execute_reply": "2023-10-15T17:44:30.624183Z"
    },
    "id": "E4KdX-fC7Jfj",
    "outputId": "0180d12f-ee19-4013-dc35-9c539bf1e387",
    "papermill": {
     "duration": 0.021764,
     "end_time": "2023-10-15T17:44:30.626979",
     "exception": false,
     "start_time": "2023-10-15T17:44:30.605215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39143490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:30.653138Z",
     "iopub.status.busy": "2023-10-15T17:44:30.652888Z",
     "iopub.status.idle": "2023-10-15T17:44:31.426049Z",
     "shell.execute_reply": "2023-10-15T17:44:31.425023Z"
    },
    "id": "3XbG2gW9MLJ0",
    "papermill": {
     "duration": 0.790634,
     "end_time": "2023-10-15T17:44:31.430469",
     "exception": false,
     "start_time": "2023-10-15T17:44:30.639835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_path = '../features/features.pkl'\n",
    "with open(features_path, 'rb') as file:\n",
    "    features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7cbddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:31.459965Z",
     "iopub.status.busy": "2023-10-15T17:44:31.459676Z",
     "iopub.status.idle": "2023-10-15T17:44:31.499246Z",
     "shell.execute_reply": "2023-10-15T17:44:31.498200Z"
    },
    "id": "0XtpL7hGb7q3",
    "papermill": {
     "duration": 0.057917,
     "end_time": "2023-10-15T17:44:31.501714",
     "exception": false,
     "start_time": "2023-10-15T17:44:31.443797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir, 'captions.txt'), 'r') as f:\n",
    "    next(f)\n",
    "    captions_doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa40d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:31.529527Z",
     "iopub.status.busy": "2023-10-15T17:44:31.529217Z",
     "iopub.status.idle": "2023-10-15T17:44:31.619109Z",
     "shell.execute_reply": "2023-10-15T17:44:31.617861Z"
    },
    "id": "DSdYIfRHlMd8",
    "outputId": "719014ab-000f-44ca-9756-d198c8f66153",
    "papermill": {
     "duration": 0.241783,
     "end_time": "2023-10-15T17:44:31.756862",
     "exception": false,
     "start_time": "2023-10-15T17:44:31.515079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "captions_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc296d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:31.863070Z",
     "iopub.status.busy": "2023-10-15T17:44:31.862489Z",
     "iopub.status.idle": "2023-10-15T17:44:31.920911Z",
     "shell.execute_reply": "2023-10-15T17:44:31.919999Z"
    },
    "id": "jYD-GXuqUq32",
    "papermill": {
     "duration": 0.114389,
     "end_time": "2023-10-15T17:44:31.922694",
     "exception": false,
     "start_time": "2023-10-15T17:44:31.808305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create mapping of image to captions\n",
    "mapping = {}\n",
    "# process lines\n",
    "for line in captions_doc.split('\\n'):\n",
    "    # split the line by comma(,)\n",
    "    tokens = line.split(',')\n",
    "    if len(line) < 2:\n",
    "        continue\n",
    "    image_id, caption = tokens[0], tokens[1:]\n",
    "    # remove extension from image ID\n",
    "    image_id = image_id.split('.')[0]\n",
    "    # convert caption list to string\n",
    "    caption = \" \".join(caption)\n",
    "    # create list if needed\n",
    "    if image_id not in mapping:\n",
    "        mapping[image_id] = []\n",
    "    # store the caption\n",
    "    mapping[image_id].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838f93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.029902Z",
     "iopub.status.busy": "2023-10-15T17:44:32.029387Z",
     "iopub.status.idle": "2023-10-15T17:44:32.036585Z",
     "shell.execute_reply": "2023-10-15T17:44:32.035684Z"
    },
    "id": "O4Oy3a8db0V0",
    "outputId": "960121cb-c1fc-4539-fa5b-0b51412c6fb1",
    "papermill": {
     "duration": 0.064769,
     "end_time": "2023-10-15T17:44:32.038456",
     "exception": false,
     "start_time": "2023-10-15T17:44:31.973687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping[list(mapping.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63716afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.142864Z",
     "iopub.status.busy": "2023-10-15T17:44:32.142379Z",
     "iopub.status.idle": "2023-10-15T17:44:32.148757Z",
     "shell.execute_reply": "2023-10-15T17:44:32.147854Z"
    },
    "id": "8pv4ELabcSBs",
    "outputId": "4b84eac3-0f5f-4c3d-f89f-8b5aa4d548df",
    "papermill": {
     "duration": 0.060941,
     "end_time": "2023-10-15T17:44:32.150437",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.089496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9659f",
   "metadata": {
    "id": "aU8BPQ8AmGYa",
    "papermill": {
     "duration": 0.05633,
     "end_time": "2023-10-15T17:44:32.256839",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.200509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e405a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.363161Z",
     "iopub.status.busy": "2023-10-15T17:44:32.362658Z",
     "iopub.status.idle": "2023-10-15T17:44:32.367804Z",
     "shell.execute_reply": "2023-10-15T17:44:32.366754Z"
    },
    "id": "mRoORBrpgRub",
    "papermill": {
     "duration": 0.061106,
     "end_time": "2023-10-15T17:44:32.369542",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.308436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def clean(mapping):\n",
    "#   for key,captions in mapping.items():\n",
    "#     for i in range(len(captions)):\n",
    "#       caption=captions[i]\n",
    "#       caption=caption.lower()\n",
    "#       caption=caption.replace('[^A-Za-z]', '')\n",
    "#       caption=caption.replace('\\s+', ' ')\n",
    "#       caption='startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n",
    "#       caption[i]=caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29401fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.472144Z",
     "iopub.status.busy": "2023-10-15T17:44:32.471304Z",
     "iopub.status.idle": "2023-10-15T17:44:32.478146Z",
     "shell.execute_reply": "2023-10-15T17:44:32.477298Z"
    },
    "id": "6mNAZRAcpUVC",
    "papermill": {
     "duration": 0.061031,
     "end_time": "2023-10-15T17:44:32.479894",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.418863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(mapping):\n",
    "    for key, captions in mapping.items():\n",
    "        for i in range(len(captions)):\n",
    "            # take one caption at a time\n",
    "            caption = captions[i]\n",
    "            # preprocessing steps\n",
    "            # convert to lowercase\n",
    "            caption = caption.lower()\n",
    "            # delete digits, special chars, etc.,\n",
    "            caption = caption.replace('[^A-Za-z]', '')\n",
    "            # delete additional spaces\n",
    "            caption = caption.replace('\\s+', ' ')\n",
    "            # add start and end tags to the caption\n",
    "            caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n",
    "            #caption = \" \".join([word for word in caption.split() if len(word)>1])\n",
    "            #caption = caption.capitalize()\n",
    "            captions[i] = caption\n",
    "            #caption = caption.capitalize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9acacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.580844Z",
     "iopub.status.busy": "2023-10-15T17:44:32.580380Z",
     "iopub.status.idle": "2023-10-15T17:44:32.586404Z",
     "shell.execute_reply": "2023-10-15T17:44:32.585555Z"
    },
    "id": "1C140RcPl0Dt",
    "outputId": "5df5f108-01e3-4a68-fd16-7cae05c0402b",
    "papermill": {
     "duration": 0.060285,
     "end_time": "2023-10-15T17:44:32.588137",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.527852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#befor preprocess of text\n",
    "mapping['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cc0d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.696680Z",
     "iopub.status.busy": "2023-10-15T17:44:32.696246Z",
     "iopub.status.idle": "2023-10-15T17:44:32.796978Z",
     "shell.execute_reply": "2023-10-15T17:44:32.795865Z"
    },
    "id": "gk7Sc-RLo4gb",
    "papermill": {
     "duration": 0.159757,
     "end_time": "2023-10-15T17:44:32.798883",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.639126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprocess the text\n",
    "clean(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c41b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:32.904018Z",
     "iopub.status.busy": "2023-10-15T17:44:32.901974Z",
     "iopub.status.idle": "2023-10-15T17:44:32.908866Z",
     "shell.execute_reply": "2023-10-15T17:44:32.907922Z"
    },
    "id": "CeLjMj2bl0HL",
    "outputId": "3271b19f-3138-4c3e-c0ae-b401e3d97fb1",
    "papermill": {
     "duration": 0.062043,
     "end_time": "2023-10-15T17:44:32.910599",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.848556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#after preprocess the text\n",
    "mapping['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119036e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:33.013337Z",
     "iopub.status.busy": "2023-10-15T17:44:33.012895Z",
     "iopub.status.idle": "2023-10-15T17:44:33.026255Z",
     "shell.execute_reply": "2023-10-15T17:44:33.025212Z"
    },
    "id": "Jm1JNNBAow1Z",
    "papermill": {
     "duration": 0.068526,
     "end_time": "2023-10-15T17:44:33.027940",
     "exception": false,
     "start_time": "2023-10-15T17:44:32.959414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_captions=[]\n",
    "for key in mapping:\n",
    "  for caption in mapping[key]:\n",
    "    all_captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54cfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:33.133054Z",
     "iopub.status.busy": "2023-10-15T17:44:33.132568Z",
     "iopub.status.idle": "2023-10-15T17:44:33.139206Z",
     "shell.execute_reply": "2023-10-15T17:44:33.138348Z"
    },
    "id": "1Zx1Qyopq0Y7",
    "outputId": "6429f52d-2395-476b-c474-e76b1cab41e0",
    "papermill": {
     "duration": 0.061592,
     "end_time": "2023-10-15T17:44:33.140886",
     "exception": false,
     "start_time": "2023-10-15T17:44:33.079294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "8091*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406df254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:33.250781Z",
     "iopub.status.busy": "2023-10-15T17:44:33.250292Z",
     "iopub.status.idle": "2023-10-15T17:44:33.256073Z",
     "shell.execute_reply": "2023-10-15T17:44:33.255223Z"
    },
    "id": "E_CEOOAYqlXz",
    "outputId": "63a8bc09-dadf-434a-983f-c2d5661b75c8",
    "papermill": {
     "duration": 0.065604,
     "end_time": "2023-10-15T17:44:33.257843",
     "exception": false,
     "start_time": "2023-10-15T17:44:33.192239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769220c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:33.361725Z",
     "iopub.status.busy": "2023-10-15T17:44:33.361200Z",
     "iopub.status.idle": "2023-10-15T17:44:33.367567Z",
     "shell.execute_reply": "2023-10-15T17:44:33.366721Z"
    },
    "id": "QrksMykxqpqR",
    "outputId": "d2959bd0-1882-465e-d0a0-cc5bc90dc480",
    "papermill": {
     "duration": 0.062218,
     "end_time": "2023-10-15T17:44:33.369229",
     "exception": false,
     "start_time": "2023-10-15T17:44:33.307011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_captions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f0038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:33.473182Z",
     "iopub.status.busy": "2023-10-15T17:44:33.472722Z",
     "iopub.status.idle": "2023-10-15T17:44:34.013763Z",
     "shell.execute_reply": "2023-10-15T17:44:34.012696Z"
    },
    "id": "Kr6lEjAfqu0p",
    "papermill": {
     "duration": 0.596618,
     "end_time": "2023-10-15T17:44:34.016223",
     "exception": false,
     "start_time": "2023-10-15T17:44:33.419605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenize the text\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "vocab_size=len(tokenizer.word_index)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0dd342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:34.134909Z",
     "iopub.status.busy": "2023-10-15T17:44:34.134421Z",
     "iopub.status.idle": "2023-10-15T17:44:34.141313Z",
     "shell.execute_reply": "2023-10-15T17:44:34.140410Z"
    },
    "id": "xa_MzRtzrtcU",
    "outputId": "3520a7e7-e597-4176-9438-52ed72882335",
    "papermill": {
     "duration": 0.069597,
     "end_time": "2023-10-15T17:44:34.143209",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.073612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af900d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:34.248718Z",
     "iopub.status.busy": "2023-10-15T17:44:34.248171Z",
     "iopub.status.idle": "2023-10-15T17:44:34.252649Z",
     "shell.execute_reply": "2023-10-15T17:44:34.251671Z"
    },
    "id": "quaaZLrTuMxH",
    "papermill": {
     "duration": 0.060415,
     "end_time": "2023-10-15T17:44:34.254310",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.193895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #tokenize the text\n",
    "# tokenizer=Tokenizer()\n",
    "# tokenizer.fit_on_texts(all_captions)\n",
    "# vocab_size=len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2781625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:34.371199Z",
     "iopub.status.busy": "2023-10-15T17:44:34.370696Z",
     "iopub.status.idle": "2023-10-15T17:44:34.404234Z",
     "shell.execute_reply": "2023-10-15T17:44:34.403292Z"
    },
    "id": "MaeEFzaEuQVy",
    "outputId": "8a0aaf5c-0b9c-43fc-ec70-e4d8cc3b7d5d",
    "papermill": {
     "duration": 0.096368,
     "end_time": "2023-10-15T17:44:34.406109",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.309741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get maximum length of the caption available\n",
    "max_length=max(len(caption.split()) for caption in all_captions)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99022447",
   "metadata": {
    "id": "3IbE8renv6vT",
    "papermill": {
     "duration": 0.051653,
     "end_time": "2023-10-15T17:44:34.511014",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.459361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a6c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:34.631166Z",
     "iopub.status.busy": "2023-10-15T17:44:34.630685Z",
     "iopub.status.idle": "2023-10-15T17:44:34.637235Z",
     "shell.execute_reply": "2023-10-15T17:44:34.636290Z"
    },
    "id": "G_2r6RHpujxY",
    "outputId": "f626640b-4178-4950-8ab5-873b6823baf6",
    "papermill": {
     "duration": 0.071364,
     "end_time": "2023-10-15T17:44:34.639132",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.567768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_ids=list(mapping.keys())\n",
    "split=int(len(image_ids)* .90)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba39777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:34.742553Z",
     "iopub.status.busy": "2023-10-15T17:44:34.742087Z",
     "iopub.status.idle": "2023-10-15T17:44:34.747506Z",
     "shell.execute_reply": "2023-10-15T17:44:34.746492Z"
    },
    "id": "rIaRUHXLwhz-",
    "papermill": {
     "duration": 0.06087,
     "end_time": "2023-10-15T17:44:34.749297",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.688427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=image_ids[:split]\n",
    "test=image_ids[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c70c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:34.853539Z",
     "iopub.status.busy": "2023-10-15T17:44:34.853063Z",
     "iopub.status.idle": "2023-10-15T17:44:34.861044Z",
     "shell.execute_reply": "2023-10-15T17:44:34.860048Z"
    },
    "id": "ehAFDLwFxlAY",
    "papermill": {
     "duration": 0.063322,
     "end_time": "2023-10-15T17:44:34.862830",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.799508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create data genretor\n",
    "# create data generator to get data in batch (avoids session crash)\n",
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            captions = mapping[key]\n",
    "            # process each caption\n",
    "            for caption in captions:\n",
    "                # encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # split the sequence into X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pairs\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                    # store the sequences\n",
    "                    X1.append(features[key][0])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            if n == batch_size:\n",
    "                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                yield [X1, X2], y\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaf63c",
   "metadata": {
    "id": "Zf8LIMC3683i",
    "papermill": {
     "duration": 0.052123,
     "end_time": "2023-10-15T17:44:34.963587",
     "exception": false,
     "start_time": "2023-10-15T17:44:34.911464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb660c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:35.076219Z",
     "iopub.status.busy": "2023-10-15T17:44:35.075399Z",
     "iopub.status.idle": "2023-10-15T17:44:36.360454Z",
     "shell.execute_reply": "2023-10-15T17:44:36.358270Z"
    },
    "id": "9FlJsEUM64dP",
    "outputId": "15acee10-a1bf-4ac6-a84b-892159158d6a",
    "papermill": {
     "duration": 1.352063,
     "end_time": "2023-10-15T17:44:36.372496",
     "exception": false,
     "start_time": "2023-10-15T17:44:35.020433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoder model\n",
    "inputs1=Input(shape=(4096,))\n",
    "fe1=Dropout(.4)(inputs1)\n",
    "fe2=Dense(256,activation=\"relu\")(fe1)\n",
    "\n",
    "#sequence feature layers\n",
    "inputs2=Input(shape=(max_length,))\n",
    "se1=Embedding(vocab_size,256,mask_zero=True)(inputs2)\n",
    "se2=Dropout(0.4)(se1)\n",
    "se3=LSTM(256)(se2)\n",
    "#seqeunce feature layers\n",
    "decoder1=add([fe2,se3])\n",
    "decoder2=Dense(256,activation=\"relu\")(decoder1)\n",
    "outputs=Dense(vocab_size,activation=\"softmax\")(decoder2)\n",
    "\n",
    "model=Model(inputs=[inputs1,inputs2],outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#plot the model\n",
    "plot_model(model,show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238e25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T17:44:36.504576Z",
     "iopub.status.busy": "2023-10-15T17:44:36.504060Z"
    },
    "id": "S8Hjxyh37ZbJ",
    "outputId": "29ea1f6f-2042-4cb0-b68d-7e4dec178709",
    "papermill": {
     "duration": 3081.723778,
     "end_time": "2023-10-15T18:35:58.166797",
     "exception": false,
     "start_time": "2023-10-15T17:44:36.443019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "steps = len(train) // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    # create data generator\n",
    "    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
    "    # fit for one epoch\n",
    "    #model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42162f",
   "metadata": {
    "id": "4tqOpG2xAOk7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"best_mode_vgg_40.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ffacb",
   "metadata": {
    "id": "XOnQiyIzATdB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_mode_vgg_40.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c532087",
   "metadata": {
    "id": "MRGMtmS1pkL1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # saving\n",
    "# with open('tokenizer40_new.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tokenizer, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e085b",
   "metadata": {
    "id": "2wqLjLGaAXFy",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# saving\n",
    "with open('tokenizer40.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e09368",
   "metadata": {
    "id": "YJgiBz-9AXPx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('tokenizer40.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0f008",
   "metadata": {
    "id": "UbrtWhwbTldA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## generate cation for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f5c89",
   "metadata": {
    "id": "PK2P00tNJGvp",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6776b60",
   "metadata": {
    "id": "YQRZ1hRuTiTm",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate caption for an image\n",
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        # encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad the sequence\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        # get index with high probability\n",
    "        yhat = np.argmax(yhat)\n",
    "        # convert index to word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        # stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        # append word as input for generating next word\n",
    "        in_text += \" \" + word\n",
    "        # stop if we reach end tag\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44467d2f",
   "metadata": {
    "id": "O6ootw6Plxhq",
    "outputId": "f8478588-8bd4-472b-b0b6-8700da35a0f8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "# validate with test data\n",
    "actual, predicted = list(), list()\n",
    "\n",
    "for key in tqdm(test):\n",
    "    # get actual caption\n",
    "    captions = mapping[key]\n",
    "    # predict the caption for image\n",
    "    y_pred = predict_caption(model, features[key], tokenizer, max_length)\n",
    "    # split into words\n",
    "    actual_captions = [caption.split() for caption in captions]\n",
    "    y_pred = y_pred.split()\n",
    "    # append to the list\n",
    "    actual.append(actual_captions)\n",
    "    predicted.append(y_pred)\n",
    "\n",
    "# calcuate BLEU score\n",
    "print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64024a",
   "metadata": {
    "id": "ir47IS2Jbvg6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_caption(image_name):\n",
    "    # load the image\n",
    "    image_name = \"667626_18933d713e.jpg\"\n",
    "    image_id = image_name.split('.')[0]\n",
    "    img_path = os.path.join(base_dir, \"Images\", image_name)\n",
    "    image = Image.open(img_path)\n",
    "    captions = mapping[image_id]\n",
    "    print('---------------------Actual---------------------')\n",
    "    for caption in captions:\n",
    "        print(caption)\n",
    "    # predict the caption\n",
    "    plt.imshow(image)\n",
    "    y_pred = predict_caption(model, features[image_id], tokenizer, max_length)\n",
    "    print('--------------------Predicted--------------------')\n",
    "\n",
    "    print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c844982",
   "metadata": {
    "id": "REV0l27-JX4A",
    "outputId": "739d2c60-18d3-45d5-eee5-d0e8f2aa97a6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/1016887272_03199f49c4.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd689b7",
   "metadata": {
    "id": "1MorS56O3Vq5",
    "outputId": "62bde396-5db5-4a8a-c358-7584e3b9587c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/1002674143_1b742ab4b8.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccd544",
   "metadata": {
    "id": "7z5_rzpLAX5X",
    "outputId": "5b901f1a-d267-4e32-dc01-b2dc29f7dc67",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/102351840_323e3de834.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9b83a",
   "metadata": {
    "id": "IGZ3HGLh_IvV",
    "outputId": "fc83bf56-4a49-45c6-93c8-8ffde5cb3b71",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/1093716555_801aacef79.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac7b8b",
   "metadata": {
    "id": "ZoNUIRvi_I9x",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7e7f2",
   "metadata": {
    "id": "wtn9NlCp8pmz",
    "outputId": "c715f60e-0f59-4e58-9945-acc2f0999172",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/1077546505_a4f6c4daa9.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2654b9b",
   "metadata": {
    "id": "3llXR7Oy7UFL",
    "outputId": "10b30719-dcb4-4838-d830-01fc0767021b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/109202801_c6381eef15.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704b094",
   "metadata": {
    "id": "3nklMIlR3pVA",
    "outputId": "9f86ffc4-9348-43d7-e8b7-35ea781e04da",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/1094462889_f9966dafa6.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad040425",
   "metadata": {
    "id": "4HeYkC8gl4GR",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b48aa",
   "metadata": {
    "id": "kct9bxndWcvo",
    "outputId": "a8d3e499-6518-4bf1-a7f3-aa3be1a29525",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_caption(\"3707990914_843e8f15f1.jpg\")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize the image to match VGG16 input size\n",
    "    image = np.array(image)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def generate_caption_for_new_image(image_path):\n",
    "    # Preprocess the image\n",
    "    new_image = preprocess_image(image_path)\n",
    "\n",
    "    # Generate features for the new image using the pre-trained VGG16 model\n",
    "    vgg_model = VGG16()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "    new_image_features = vgg_model.predict(np.array([new_image]), verbose=0)\n",
    "\n",
    "    # Predict caption for the new image\n",
    "    predicted_caption = predict_caption(model, new_image_features, tokenizer, max_length)  #loaded_model, new_image_features, loaded_tokenizer,\n",
    "\n",
    "    # Remove startseq and endseq tokens\n",
    "    predicted_caption = predicted_caption.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "    # Capitalize the first letter\n",
    "    predicted_caption = predicted_caption.capitalize()\n",
    "\n",
    "    # Add a full stop at the end if not present\n",
    "    if not predicted_caption.endswith('.'):\n",
    "        predicted_caption += '.'\n",
    "\n",
    "    # Display the image and the predicted caption\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(predicted_caption)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Specify the path to the new image\n",
    "new_image_path = \"../flickr8k/Images/1082379191_ec1e53f996.jpg\"\n",
    "generate_caption_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb411c",
   "metadata": {
    "id": "Iu_RRCBQW9r6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3739.258708,
   "end_time": "2023-10-15T18:35:58.714983",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-15T17:33:39.456275",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
